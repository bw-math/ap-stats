.. _point_estimation:

================
Point Estimation
================

A sample of data is characterized by *point estimates* of *sample statistics*.

Definitions
===========

.. _observation:

Observation
-----------

Symbolic Expression
    :math:`x_i`

Definition
    An :ref:`individual`; A single piece of data. 
    
The subscript *i* is called the *index* of the observation. If the sample is ordered, the *index* corresponds to the order in which the observation was made, i.e. :math:`x_1` is the first observation, :math:`x_2` is the second observation, etc. 

.. _sample:

Sample
------

Symbolic Expression 
    :math:`\{ x_1, x_2, ..., x_{n-1}, x_n \}`

Definition 
    A collection, or :ref:`set <set_theory>`, of observations. 
    
The number of samples, *n*, is called the *sample size*.

.. _frequency:

Frequency
---------

Symbolic Expression
    :math:`f(x_i)`

Definition
    The number of times a particular observation occurs in a sample of data.

.. _outlier:

Outlier
-------

Definition
    An unusual observation.

What we mean by "*unusual*" depends on the data. GEnerally speaking, we mean something that roughly approximates, "*a data that is far outside what is expected*".

If we are measuring :ref:`numerical data <data_characteristic>`, this might mean an observation that is much, much greater than or much, much less than the majority of the data. 

If we are measuring :ref:`categorical data <data_characteristic>`, this might mean an observation is in infrequent.

.. _floor_function:

Floor Function 
--------------

Symbolic Expression
    .. math::

        \lfloor x \rfloor

Definition
    The *floor function* returns the integer-valued part of a number. In other words, it removes the decimal from a number.


Example
    .. math::

        \lfloor 4.5 \rfloor = 4

.. _ceiling_function:

Ceiling Function
----------------

Symbolic Expression 
    .. math::

        \lceil x \rceil 

Definition 
    The *ceiling* returns the next largest integer. In other words, it always rounds *up*.


Example 
    .. math::

        \lceil 4.5 \rceil = 5

.. _measures_of_centrality:

Measures of Centrality 
======================

*Measures of centrality*, sometimes known as *measures of central tendency*, describe *where* the "*center*" of a sample of data is located. What we mean by "*center*" is, in some sense, left to the reader's intuition. A good analogy for the statistical conception of *centrality* comes from the field of physics: the idea of `center of mass <https://en.wikipedia.org/wiki/Center_of_mass>`_. The *center of mass* is the *balance point*, the point around which a body of mass is distributed so the torque generated by gravity is held is equilibrium. In this analogy, the *mass* is the *sample of data*. *Centrality* in a *sample* is a measure of its "*center of mass*", so to speak.  

.. _arithmetic_mean:

Arithmetic Mean
---------------

The *arithmetic* mean is a sample statistic you have probably seen before; what you probably didn't know is it is not the *only* way of calculating the mean. You will see in the next few sections alternate ways of calculating a quantity that is meant to represent the *mean* of a sample. Each of these :ref:`sample statistics<sample_statistic>` represents a way of quantifying the notion of "*central tendency*"

Before getting to the good stuff, let's review the *arithmetic* mean. There are two equivalent ways of defining the *sample mean*. 

.. _sample_mean_formula:

Sample Formula
**************

If the sample of data is specified as a set or list of data as in the following, 

.. math:: 
    S = \{ x_1, x_2, ... , x_n \}

Then the sample arithmetic mean can be calculated with the formula,

.. math::
    \bar{x} = \frac{\sum_{i}^n x_i}{n}

This is known as the *sample mean formula* for the arithmetic mean.

Example
    Suppose you survey 10 people and ask them how many of the 11 full-length, major motion picture *Star Wars* movies they have seen. Suppose the sample **S** of their responses is given below,

    .. math::
        S = \{ 6, 7, 9, 0, 1, 0, 3, 6, 3, 9 \}

    Find the average number of *Star Wars* movies seen by this sample of people.

Applying the *sample mean formula*,
    
.. math::

    \bar{x} = \frac{6 + 7 + 9 + 0 + 1 + 0 + 3 + 6 + 3 + 9}{10} = 3.5 movies

.. note::
    
    Notice in this example the *sample mean* does **not** correspond to an observable value in the sample. 
    
    The *sample mean* is not even a *possible value* of an individual observation in this sample (unless we allow for people who stopped watching half-way through one of the movies).

Interlude
*********

Suppose in a sample of data **S**, some of the observations have identical values, such as in the following dataset that represents the age in years of an A.P Statistics student,

    S = \{ 16, 16, 17, 18, 16, 17, 17, 17 \}

Before moving on to calculate the sample mean, let us represent this sample **S** in an equivalent way using a table,

+--------------+----------------+
|  :math:`x_i` | :math:`f(x_i)` |
+--------------+----------------+
|      16      |       3        |
+--------------+----------------+
|      17      |       4        |
+--------------+----------------+
|      18      |       1        |
+--------------+----------------+

This way of representing a sample of data, where the first column stands for the value of the observation and the second column that stands for the frequency of that observation, is known as a :ref:`frequency_distributions`. 

(We will study *frequency distributions* in more detail in the :ref:`next section <graphical_representations_of_data>`.)

Let us move on to the task at hand: calculating the sample mean. In this case, the formula for the arithmetic mean gives,

.. math:: 
    \bar{x} = \frac{16 + 16 + 17 + 18 + 16 + 17 + 17 + 17}{8}

If we collect all the terms in the numerator that are *like*, we may rewrite this as,

.. math::
    \bar{x} = \frac{3 \cdot 16 + 4 \cdot 17 + 1 \cdot 18}{8}

Notice the first factor of each term in the numerator is simply frequency of that observation in the *frequency distribution* table, whereas the second factor is the actual value of the observation. In other words, each term of the numerator is of the form,

.. math::
    x_i \cdot f(x_i)

This recognization leads the following formula that comes in handy when sample distributions are given in terms of :ref:`frequency distributions <frequency_distributions>`

.. _sample_mean_frequency_formula:

Frequency Formula
*****************

If the sample of data is specified as a frequency distribution as in the following,

+-------------+-------------------+
|     x       |      f(x)         |
+=============+===================+
|  x :sub:`0` |   f( x :sub:`0`)  |
+-------------+-------------------+
|  x :sub:`1` |   f( x :sub:`1`)  |
+-------------+-------------------+
|  ...        |  ...              |
+-------------+-------------------+
|  x :sub:`n` |   f( x :sub:`n`)  |
+-------------+-------------------+

Then the sample arithmetic mean can be calculated with the formula, 

.. math::
    \bar{x}_A = \sum_{i}^n x_i \cdot f(x_i)

Example
    TODO 

+--------------+----------------+
|  :math:`x_i` | :math:`f(x_i)` |
+--------------+----------------+
|      ??      |       ?        |
+--------------+----------------+
|      ??      |       ?        |
+--------------+----------------+
|      ??      |       ?        |
+--------------+----------------+

.. _geometric_mean:

Geometric Mean
--------------

The *geometric mean* is an alternate way of defining the *mean* of a sample data. 

The *geometric mean* is defined as,

.. math::
    \bar{x}_G = (x_1 \cdot x_2 \cdot ... \cdot x_{n-1} \cdot x_n )^(1/n)

TODO 

.. _geometric_vs_arithmetic_mean:

Geometric vs. Arithmetic Mean
*****************************

TODO

The Moral of the Story
**********************

There are other variants of the *mean* that sometimes appear in the literature. For example, when dealing with certain types of data, the `harmonic mean <https://en.wikipedia.org/wiki/Harmonic_mean>`_ is often the most appropriate measure for *central tendency*. 

We talk about these other variants only to make you aware of them. In this class, we will exclusively be dealing with the *arithmetic mean*.

Nevertheless, before moving on, there is an important point to make: *central tendency* is not an absolute measure of a sample; its value depends on the *way* we calculate it. 

This feature of statistics may be surprising. The amount of choice we have in *how* we go about measuing the population from a sample of data may seem as if it should not lead to a rigorous and well defined branch of mathematics.

It is true the choice we make between using the geometric mean and the arithmetic mean is to some extent arbitrary; there is not a particularly good reason for preferring one over the other, besides convention (and certain other properties that make calculations easier, as we shall see in later chapters). It is not important which one we choose; it is only important *that* we choose one and stick with it.

One of the key idea of statistics is, not that we should *rid* ourselves of assumptions and biases (an impossible task), but that we should be *aware* of our assumptions and biases. Otherwise, without awareness, those assumptions and biases may show up and influence the data.

Categorical Measures
--------------------

The :ref:`arithmetic_mean` and the :ref:`geometric_mean` only apply if the data being measured is :ref:`quantitative data <data_characteristic>`. If, however, the data being measured is categorical is nature, we do not have these tools available to us. Instead, we use the next two measures of central tendency to get a picture of the distribution shape.

.. _mode:

Mode
****

Definition
    The *mode* is the most frequent of observation in a sample of data.

TODO 

Sample Proportion
*****************

Definition
    .. math::

        \hat{p} = \frac{f(x_i)}{n}

The sample proportion is the ratio of the number of individuals in the sample that share a certain property to the total number of individuals in the sample. In other words, it is the frequency of an observation divided by the the number of observations.

.. _measures_of_location:

Measures of Location
====================

.. important:: 

    Your book does not do a good job of covering this topic. 

In the :ref:`measures_of_centrality`, we drew the analogy between mass and a sample. Specifically, we proposed the following relation,

    Center of mass is to matter as measures of centrality are to a sample of data.

Extending the analogy, the center of mass is not enough to specify the *distribution of mass* in a body. We also need information about the volume (e.g. :math:`cm^3`) enclosed by the body and the density of the matter (e.g. :math:`\frac{gm}{cm^3}`) it contains.

Likewise, *measures of centrality* do not tell us the whole story about a sample. We need additional information in order to get a clearer picture of the distribution of data. *Measures of location* are a type of sample statistics that provide this information.

Order Statistics
----------------

An *order* statistic gives you information about the *ordinality* of a sample. The term "*ordinality*" refers to the *structural* or *sequential* nature of a sample. 

To see what is meant by the term *ordinality*, suppose you have a sample of :ref:`quantiative data <data_characteristic>` :math:`\{ x_i \}`,

.. math:: 

    S = \{ x_1, x_2, ..., x_i, ... , x_n \}

The *m* :sup:`th` order statistic, :math:`x_(m)` is the *m* :sup:`th` observation in the ordered sample :math:`S_(o)`,

.. math:: 

    S_(o) = \{ x_(1), x_(2), ... x_(m), ..., x_(n) \}

After the data set is sorted, the new index (subscript) ``(m)`` attached to the observation is called the *order* of the observation. 

Example
    Suppose you measure the lifetime of a sample of batteries in years. You obtain the following result,

    .. math::

        S = \{ 5.1 \text{years}, 3.2 \text{years}, 6.7 \text{years}, 1.4 \text{years} \}


Then the ordered sample :math:`S_(o)` is given

.. math:: 

    S_(o) = \{ 1.4, 3.3, 5.1, 6.7 \}

The 1 :sup:`st` *order statistic* is *1.4 years*, the 2 :sup:`nd` *order statistic* is *3.3 years*, the 3 :sup:`rd` *order statistic* is *5.1 years* and the 4 :sup:`th` *order statistic* is *6.7 years*. Another way of saying this would be the *order* of *1.4 years* is 1, the *order* of *3.3 years* is 2, the *order* of *5.1 years* is 3 and the *order* of *6 years* is 4. 

*Order statistics* are important because they allows us to define more complex statistics in a precise manner. 

.. _range:

Range
*****
*****

The range is a measure of the *total variation* of a sample of data.

Definition
    The *range* of a sample of data :math:`x_i` is the difference between its last order statistic and its first order statistic, 

    .. math::

        \text{Range}(\{ x_i \}) = x_(n) - x_(1)

.. _percentile:

Percentile
**********
**********

The :math:`(p \cdot 100 \%)^{\text{th}}` *percentile* roughly means the observation in a sample with :math:`(p \cdot 100 \%)` percent of the distribution below its value. 

.. note:: 

    *p* is a fraction here.

You have probably encountered the concept of *percentiles* at some point in other classes and have developed an idea of what they represent. Teachers often express quiz and test scores in terms of percentiles to give students a sense of how they are doing relative to the rest of the class. 

The meaning of a percentile should be intuitive and straight-forward; it is a measure of *how much* of a distribution lies below a given observation. The preliminary definition of a *percentile* conforms to this intuition,

Preliminary Definition 
    If a sample of data has been ordered from lowest value to highest value, then :math:`(p \cdot 100 \%)^{\text{th}}`:sup:`th` percentile of the sample is the observation such that :math:`(p \cdot 100 \%)` percent of the sample is less than or equal that value.

From this definition, it should be clear *percentiles* only have meaning with respect to :ref:`quantitative data <data_characteristic>`. To *order* a sample of data :math:`\{ x_i \}`, the relation :math:`x_{i-1} < x_i` must have meaning. 

*Order statistics* give us a way to precisely define a percentile. *Order statistics* divide the interval on which the sample was measured into :math:`n+1` intervals, pictured below,

.. image:: ../../assets/imgs/statistics/order_statistics.jpg
    :align: center

Note all of the intervals are *below* the order statistic except the last one, which is *above* its order statistic. Hence :math:`n+1`.

The number of such intervals below a given order statistic is *equal to* to the *order* of that observation. In other words, the fraction of intervals below the *m* :sup:`th` order statistic is given by,

.. math:: 

    p = \frac{m}{n+1}

The *order m* :sup:`th` of the observation which corresponds to the :math:`(p \cdot 100 \%)^{\text{th}}` percentile can be found by solving for *m*,

Formula
    .. math::

        m = p \cdot (n+1)

We denote the order statistic :math:`x_(m)` which satisfies this formula as the :math:`\pi_p` percentile,

.. math:: 

    \pi_p = x_(m)

Example
    Suppose you were conducting a study to determine how many minutes late or early the average city bus arrived versus its scheduled time. You obtained the following data set, measured in minutes, 

    .. math::

        S = \{ 6.5 \text{min}, -2.5 \text{min}, 4.3 \text{min}, 0.5 \text{min}, 7.0 \text{min}, -1.0 \text{min}, 5.0 \text{min}, 3.0 \text{min}, -1.5 \text{min} \}

    Find the following percentiles: 20 :sup:`th` and 50 :sup:`th`

Note in this sample we have :math:`n = 9` total samples.

To find the percentiles, we need to *order* the sample from lowest to highest,

.. math:: 

    S_(o)= \{ -2.5 \text{min}, -1.5 \text{min}, -1.0 \text{min}, 0.5 \text{min}, 3.0 \text{min}, 4.3 \text{min}, 5.0 \text{min}, 6.5 \text{min}, 7.0 \text{min} \}

To find the 20 :sup:`th` percentile, :math:`pi_{.20}`, we find the *order* in which it occurs in the sample,

.. math:: 

    m = 0.20 \cdot (9 + 1) = 2

This tells us the 20 :sup:`th` percentile is the second order statistic, or in this case ``-1.5`` minutes, i.e.,

.. math:: 

    \pi_{.20} = x_(2) = -1.5 \text{min}

Similarly, to find the 50 :sup:`th` percentile, we find the *order* in which it occurs in the sample,

.. math:: 
    
    m = 0.5 \cdot (9 + 1) = 5 

Which corresponds to the fifth order statistic, or in this case, ``3.0`` minutes,

.. math:: 

    \pi_p = x_(5) = 3.0 \text{min}

Interpolation
*************

The previous example was contrived so the *order* of the sample percentile worked out to be a whole number, i.e. in both cases the formula :math:`m = (n+1) \cdot p` gave us an integer value. What happens things are not so simple?

Example
    Consider the same experiment of measuring bus waiting times, with the same sample data,

    .. math::

        S_(o)= \{ -2.5 \text{min}, -1.5 \text{min}, -1.0 \text{min}, 0.5 \text{min}, 3.0 \text{min}, 4.3 \text{min}, 5.0 \text{min}, 6.5 \text{min}, 7.0 \text{min} \}

    Find the following percentiles: 25 :sup:`th` percentile. 

When we try to apply the formula to determine the order statistic which corresponds to this percentile, we get,

.. math:: 

    m = 0.25 \cdot (9 + 1) = 2.5

There is no observation which corresponds to a fractional order. In order to estimate the percentile in this case, we use *linear interpolation*, using the *order* of the observation as the *x* variable and the value of the observation as the *y* variable. 


To do this, we take the order statistics on each side of :math:`m = 2.5`, in this case :math:`x_(2)` and :math:`x_(3)`, and find the slope of the line that connects them,

.. math:: 

    \text{slope} = \frac{x_(3) - x_(2)}{3-2} = x_(3) - x_(2)

Then we find the point on this line that corresponds to :math:`(2.5, x_(2.5))` (using the point-slope formula!), which will serve as our estimate of the 25 :sup:`th` percentile,

.. math::

    \text{slope} = \frac{x_(3) - x_(2.5)}{3 - 2.5} = x_(3) - x_(2)

Sovling this for :math:`x_(m)`, we obtain,

.. math::

    x_(2.5) = x_(3) - (x_(3) - x_(2))*(3 - 2.5)

Or equivalently (plugging :math:`x_(2)` into the point-slope formula instead of :math:`x_(3)`),

.. math:: 

    x_(2.5) = x_(2) + (x_(3) - x_(2))*(2.5 - 2)

Plugging the values in 



TODO 

This leads to a general expression for the percentile that applies whether the order *m* is a whole number or a fraction,


.. math:: 

    x_(m) = x_(\lfloor m \rfloor) + x_(\lceil m \rceil ) * (m - \lfloor m \rfloor)

TODO

.. _median:

Median
******
******

TODO

.. _quartiles: 

Quartiles
*********
*********

TODO 
        
.. _measures_of_variation:

Measures of Variation 
=====================

*Measures of variation* characterize the *spread* and *dispersion* of a sample of data.

Motivation
----------

Consider these two samples of data :math:`S_1` and :math:`S_2`,

.. math::

    S_1 = \{ 4, 5, 6 \}

.. math::

    S_2 = \{ 0, 5, 10 \}

If we apply the :ref:`Sample Mean Formula <sample_mean_formula>` to **S_1**, we get,

.. math::

    \bar{x_1} = \frac{4 + 5 + 6}{3} = 5

If we apply the :ref:`Sample Mean Formula <sample_mean_formula>` to **S_1**, we get,

.. math::

    \bar{x_2} = \frac{0 + 5 + 10}{3} = 5

In bothcases, we wind up with the same sample mean. If we summarizing these two samples of data to audience and the only information we gave them was the sample mean, they might erroneously conclude the samples were the same.

However, refering to the actual observations that make up either sample, it is clear the samples are **not** the same.

Clearly, we need some other type of :ref:`sample_statistic` to differentiate these two samples of data. 

In other words, the *sample mean* is *not enough* to completely describe a sample of data. In the language of mathematics, we say the sample mean is "*necessary, but not sufficient*" to determine a sample of data.

But what exactly is different about these two samples? If we plot the samples separately on a number line and compare, we can see what is going on more clearly,

(INSERT PICTURE)

Fom the picture, it is obvious that :math:`S_2` is more *spread out* around the mean than :math:`S_1`. To put it another way, :math:`S_1` is more tightly *clustered* around the mean than :math:`S_2`. This *spread* or *clustering* is referred to as *variation*.

The goal of the next few sections is to come up with a way of quantifying and measuring this *variation*.

.. _interquartile_range:

Interquartile Range
-------------------

First up, we have the *interquartile range*.

TODO

Rule of Thumb for Outliers
**************************

(TODO: three times IQR)

.. _absolute_variation:

Absolute Variation
------------------

TODO 

.. _sample_variance:

Variance
--------

Motivation
**********

Let us consider a rather contrived example that is nevertheless instructive. Suppose **S** a sample of data.represents 
TODO


.. _standard_deviation:

Standard Deviation
------------------

TODO

Measures of Comparision
=======================

Coefficient of Variation
------------------------

.. math:: 
    v = \frac{\bar{x}}{s} \cdot 100

Z Score
-------

.. math::
    z = \frac{x_i - \bar{x}}{s}


Outliers
========

TODO

Rule of Thumb
-------------

TODO

.. _chebyshevs_theorem:

Chebyshev's Theorem
===================

TODO